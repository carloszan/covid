{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3089a3d0",
   "metadata": {},
   "source": [
    "- [ ] Ler todos os arquivos\n",
    "- [ ] Separar por municipios\n",
    "- [ ] Aplicar funcao de limpeza\n",
    "- [ ] Salvar no banco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0f9d572",
   "metadata": {},
   "outputs": [],
   "source": [
    "PASTA = './../../dados'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6659c5",
   "metadata": {},
   "source": [
    "# Ler municipios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81b7a5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "def ler_municipios(pasta_csvs):\n",
    "    query = f\"\"\"\n",
    "        SELECT DISTINCT estado, municipio\n",
    "        FROM read_csv_auto('{pasta_csvs}/*.csv', union_by_name=true)\n",
    "        WHERE estado IS NOT NULL AND municipio IS NOT NULL\n",
    "        ORDER BY estado, municipio \n",
    "    \"\"\"\n",
    "    return duckdb.query(query).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b30607dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5570"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "municipios_df = ler_municipios(PASTA)\n",
    "\n",
    "len(municipios_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81a9f22",
   "metadata": {},
   "source": [
    "# Ler os .csvs filtrando por municipio e estado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0214fb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "def ler_csvs_filtrando_municipio(pasta_csvs, municipio, estado, nome_coluna_municipio='municipio', nome_coluna_estado='estado'):\n",
    "    query = f\"\"\"\n",
    "        SELECT *\n",
    "        FROM read_csv_auto('{pasta_csvs}/*.csv', union_by_name=true)\n",
    "        WHERE {nome_coluna_municipio} = '{municipio}' and {nome_coluna_estado} = '{estado}'\n",
    "    \"\"\"\n",
    "    return duckdb.query(query).to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a561bf9",
   "metadata": {},
   "source": [
    "# Funçao de limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd615401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suavizar(df, window_size=3, threshold=2):\n",
    "    \"\"\"\n",
    "    Smooth data by replacing outliers with previous day's casosNovos.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame with columns 'date' and 'casosNovos'\n",
    "    - window_size: number of days to consider in rolling window\n",
    "    - threshold: number of standard deviations to use for outlier detection\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with smoothed values\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying original data\n",
    "    df_smoothed = df.copy()\n",
    "    \n",
    "    # Calculate rolling statistics\n",
    "    rolling_mean = df['casosNovos'].rolling(window=window_size, center=True, min_periods=1).mean()\n",
    "    rolling_std = df['casosNovos'].rolling(window=window_size, center=True, min_periods=1).std()\n",
    "    \n",
    "    # Identify outliers (values outside mean ± threshold*std)\n",
    "    lower_bound = rolling_mean - threshold * rolling_std\n",
    "    upper_bound = rolling_mean + threshold * rolling_std\n",
    "    \n",
    "    is_outlier = (df['casosNovos'] < lower_bound) | (df['casosNovos'] > upper_bound)\n",
    "    \n",
    "    # Replace outliers with previous day's value\n",
    "    df_smoothed['casosNovos'] = df['casosNovos'].where(~is_outlier, df['casosNovos'].shift(1))\n",
    "    \n",
    "    # For the first row (no previous value), use the next value if available\n",
    "    if is_outlier.iloc[0] and len(df) > 1:\n",
    "        df_smoothed.iloc[0, df_smoothed.columns.get_loc('casosNovos')] = df['casosNovos'].iloc[1]\n",
    "    \n",
    "    return df_smoothed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd406963",
   "metadata": {},
   "source": [
    "# Recalcula casos acumulados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd8003e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recalcula_casos_acumulados(df):\n",
    "  df['novos_casos_acumulados'] = df['casosNovos'].cumsum()\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c170c718",
   "metadata": {},
   "source": [
    "# Função de limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a37eb134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpar(df):\n",
    "  df = suavizar(df)\n",
    "  df = recalcula_casos_acumulados(df)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5fc0bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AC_Acrelândia salvos\n",
      "AC_Assis Brasil salvos\n",
      "AC_Brasiléia salvos\n",
      "AC_Bujari salvos\n",
      "AC_Capixaba salvos\n",
      "AC_Cruzeiro do Sul salvos\n",
      "AC_Epitaciolândia salvos\n",
      "AC_Feijó salvos\n",
      "AC_Jordão salvos\n",
      "AC_Manoel Urbano salvos\n",
      "AC_Marechal Thaumaturgo salvos\n",
      "AC_Mâncio Lima salvos\n",
      "AC_Plácido de Castro salvos\n",
      "AC_Porto Acre salvos\n",
      "AC_Porto Walter salvos\n",
      "AC_Rio Branco salvos\n",
      "AC_Rodrigues Alves salvos\n",
      "AC_Santa Rosa do Purus salvos\n",
      "AC_Sena Madureira salvos\n",
      "AC_Senador Guiomard salvos\n",
      "AC_Tarauacá salvos\n",
      "AC_Xapuri salvos\n",
      "AL_Anadia salvos\n",
      "AL_Arapiraca salvos\n",
      "AL_Atalaia salvos\n",
      "AL_Barra de Santo Antônio salvos\n",
      "AL_Barra de São Miguel salvos\n",
      "AL_Batalha salvos\n",
      "AL_Belo Monte salvos\n",
      "AL_Belém salvos\n",
      "AL_Boca da Mata salvos\n",
      "AL_Branquinha salvos\n",
      "AL_Cacimbinhas salvos\n",
      "AL_Cajueiro salvos\n",
      "AL_Campestre salvos\n",
      "AL_Campo Alegre salvos\n",
      "AL_Campo Grande salvos\n",
      "AL_Canapi salvos\n",
      "AL_Capela salvos\n",
      "AL_Carneiros salvos\n",
      "AL_Chã Preta salvos\n",
      "AL_Coité do Nóia salvos\n",
      "AL_Colônia Leopoldina salvos\n",
      "AL_Coqueiro Seco salvos\n",
      "AL_Coruripe salvos\n",
      "AL_Craíbas salvos\n",
      "AL_Delmiro Gouveia salvos\n",
      "AL_Dois Riachos salvos\n",
      "AL_Estrela de Alagoas salvos\n",
      "AL_Feira Grande salvos\n",
      "AL_Feliz Deserto salvos\n",
      "AL_Flexeiras salvos\n",
      "AL_Girau do Ponciano salvos\n",
      "AL_Ibateguara salvos\n",
      "AL_Igaci salvos\n",
      "AL_Igreja Nova salvos\n",
      "AL_Inhapi salvos\n",
      "AL_Jacaré dos Homens salvos\n",
      "AL_Jacuípe salvos\n",
      "AL_Japaratinga salvos\n",
      "AL_Jaramataia salvos\n",
      "AL_Jequiá da Praia salvos\n",
      "AL_Joaquim Gomes salvos\n",
      "AL_Jundiá salvos\n",
      "AL_Junqueiro salvos\n",
      "AL_Lagoa da Canoa salvos\n",
      "AL_Limoeiro de Anadia salvos\n",
      "AL_Maceió salvos\n",
      "AL_Major Isidoro salvos\n",
      "AL_Mar Vermelho salvos\n",
      "AL_Maragogi salvos\n",
      "AL_Maravilha salvos\n",
      "AL_Marechal Deodoro salvos\n",
      "AL_Maribondo salvos\n",
      "AL_Mata Grande salvos\n",
      "AL_Matriz de Camaragibe salvos\n",
      "AL_Messias salvos\n",
      "AL_Minador do Negrão salvos\n",
      "AL_Monteirópolis salvos\n",
      "AL_Murici salvos\n",
      "AL_Novo Lino salvos\n"
     ]
    },
    {
     "ename": "ParserException",
     "evalue": "Parser Error: syntax error at or near \"Água\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mParserException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m municipio = municipios_df.at[i, \u001b[33m'\u001b[39m\u001b[33mmunicipio\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      5\u001b[39m estado = municipios_df.at[i, \u001b[33m'\u001b[39m\u001b[33mestado\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m df = \u001b[43mler_csvs_filtrando_municipio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPASTA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmunicipio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestado\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m df = limpar(df)\n\u001b[32m      9\u001b[39m df.to_csv(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33msaida/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestado\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmunicipio\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mler_csvs_filtrando_municipio\u001b[39m\u001b[34m(pasta_csvs, municipio, estado, nome_coluna_municipio, nome_coluna_estado)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mler_csvs_filtrando_municipio\u001b[39m(pasta_csvs, municipio, estado, nome_coluna_municipio=\u001b[33m'\u001b[39m\u001b[33mmunicipio\u001b[39m\u001b[33m'\u001b[39m, nome_coluna_estado=\u001b[33m'\u001b[39m\u001b[33mestado\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m      5\u001b[39m     query = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[33m        SELECT *\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33m        FROM read_csv_auto(\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpasta_csvs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/*.csv\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, union_by_name=true)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33m        WHERE \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnome_coluna_municipio\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m = \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmunicipio\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnome_coluna_estado\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m = \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestado\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[33m    \u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mduckdb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m.to_df()\n",
      "\u001b[31mParserException\u001b[39m: Parser Error: syntax error at or near \"Água\""
     ]
    }
   ],
   "source": [
    "OUTPUT_FOLDER = 'saida/'\n",
    "\n",
    "for i in range(len(municipios_df)):\n",
    "  municipio = municipios_df.at[i, 'municipio']\n",
    "  estado = municipios_df.at[i, 'estado']\n",
    "  df = ler_csvs_filtrando_municipio(PASTA, municipio, estado)\n",
    "  df = limpar(df)\n",
    "\n",
    "  df.to_csv(f'saida/{estado}_{municipio}.csv')\n",
    "  print(f\"{estado}_{municipio} salvos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
